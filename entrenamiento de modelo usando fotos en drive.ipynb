{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"entrenamiento de modelo usando fotos en drive.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP6JG9g0l05EYRUDlsos6xk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFW6xSYY2GDa","executionInfo":{"status":"ok","timestamp":1643929711462,"user_tz":240,"elapsed":3606,"user":{"displayName":"Ivan Jose Duque Luna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJhoMRg6vZLPIXpslz4bHdxaLre7D1LZX_BfQT=s64","userId":"01917523343114875724"}},"outputId":"792f74cc-371f-4501-a10b-42c5e9d6cbaf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.23.1)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"]}]},{"cell_type":"code","source":["!pip install opencv-python-headless==4.5.2.52"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOizqlbPAyz1","executionInfo":{"status":"ok","timestamp":1643929717418,"user_tz":240,"elapsed":3483,"user":{"displayName":"Ivan Jose Duque Luna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJhoMRg6vZLPIXpslz4bHdxaLre7D1LZX_BfQT=s64","userId":"01917523343114875724"}},"outputId":"a139a0a4-4272-4071-c5ac-88db77f8421b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python-headless==4.5.2.52 in /usr/local/lib/python3.7/dist-packages (4.5.2.52)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.19.5)\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1vd-qy2aNB7","executionInfo":{"status":"ok","timestamp":1643929808567,"user_tz":240,"elapsed":79326,"user":{"displayName":"Ivan Jose Duque Luna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJhoMRg6vZLPIXpslz4bHdxaLre7D1LZX_BfQT=s64","userId":"01917523343114875724"}},"outputId":"fe9b895c-1d57-4c58-d45c-9f10a9cdcdaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `2.x   # Para garantizar que la versión 2.x sea importada`. This will be interpreted as: `2.x`.\n","\n","\n","TensorFlow 2.x selected.\n","Mounted at /content/gdrive\n","erika\n","ivan\n","diego\n","['erika', 'ivan', 'diego']\n","0\n","1\n","2\n","(2250, 300, 300, 1)\n","(2250,)\n"]}],"source":["%tensorflow_version 2.x   # Para garantizar que la versión 2.x sea importada\n","#print(tf.__version__)\n","import tensorflow as tf\n","from google.colab import drive\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n","import pickle\n","import random \n","import cv2\n","import os\n","import numpy as np\n","\n","drive.mount('/content/gdrive')\n","directorio = \"gdrive/My Drive/tesis/fotos/carass\"\n","personas = []\n","carpetas_personas = os.listdir(directorio)\n","\n","for imagen in carpetas_personas:\n","    nombre = os.path.splitext(imagen)[0]\n","    print(nombre)\n","    personas.append(nombre)\n","data_entrenamiento = []\n","\n","print(personas)\n","\n","def crear_entrenamiento_datos():\n","        for persona in personas:\n","            ruta = os.path.join(directorio, persona)\n","            class_num = personas.index(persona)\n","            print(class_num)\n","\n","            for foto in os.listdir(ruta):\n","                \n","                try:\n","                    \n","                    matriz_foto = cv2.imread(os.path.join(ruta,foto), cv2.IMREAD_GRAYSCALE)\n","                    matriz_redimensionada = cv2.resize(matriz_foto, (300,300))\n","                    data_entrenamiento.append([matriz_redimensionada, class_num])\n","                    \n","                \n","                except Exception as e:\n","                    pass\n","\n","crear_entrenamiento_datos()\n","\n","random.shuffle(data_entrenamiento)\n","\n","x = []\n","y = []\n","\n","\n","for caracteristicas, etiqueta in data_entrenamiento:\n","    x.append(caracteristicas)\n","    y.append(etiqueta)\n","\n","x = np.array(x).reshape(-1, 300, 300, 1)\n","y = np.array(y)\n","\n","print(x.shape)\n","print(y.shape)\n","x = x/255.0\n","\n","pickle_out = open(\"nombres.pickle\",\"wb\")\n","pickle.dump(personas, pickle_out)\n","pickle_out.close()\n","\n","# esto se usa para tranformar la codificacion de las etiquetas de enteros a one-hot\n","#con el fin de usar categorical_crossentropy\n","#y = tf.keras.utils.to_categorical(y, num_classes=3)"]},{"cell_type":"code","source":["modelo = Sequential()\n","\n","modelo.add(Conv2D(128, (3, 3), input_shape=x.shape[1:], padding=\"same\"))\n","modelo.add(Activation('relu'))\n","modelo.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelo.add(Conv2D(128, (3, 3), (1, 1), padding=\"same\"))\n","modelo.add(Activation('relu'))\n","modelo.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelo.add(Conv2D(256, (3, 3), (1, 1), padding=\"same\"))\n","modelo.add(Activation('relu'))\n","modelo.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelo.add(Flatten())\n","\n","modelo.add(Dense(128))\n","modelo.add(Activation('relu'))\n","\n","modelo.add(Dense(128))\n","modelo.add(Activation('relu'))\n","\n","modelo.add(Dense(3))\n","modelo.add(Activation('softmax'))\n","\n","modelo.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","modelo.summary()\n","\n","modelo.fit(x, y, batch_size=10, epochs=5, validation_split=0.4)\n","\n","#modelo.save('gdrive/My Drive/tesis/modelos/modelo er-iv-di conv2d (128,128,256)(64,128,128) colab 300x300')\n","#modelo.save('gdrive/My Drive/tesis/modelos/modelo ivan-erika-diego colab 300x300')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saGXb4Xlbaqb","executionInfo":{"status":"ok","timestamp":1643819253031,"user_tz":240,"elapsed":204051,"user":{"displayName":"Ivan Jose Duque Luna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJhoMRg6vZLPIXpslz4bHdxaLre7D1LZX_BfQT=s64","userId":"01917523343114875724"}},"outputId":"87bd88ef-2085-46ab-c9ba-9d809fc3881d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_6 (Conv2D)           (None, 300, 300, 128)     1280      \n","                                                                 \n"," activation_12 (Activation)  (None, 300, 300, 128)     0         \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 150, 150, 128)    0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 150, 150, 128)     147584    \n","                                                                 \n"," activation_13 (Activation)  (None, 150, 150, 128)     0         \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 75, 75, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 75, 75, 256)       295168    \n","                                                                 \n"," activation_14 (Activation)  (None, 75, 75, 256)       0         \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 37, 37, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_2 (Flatten)         (None, 350464)            0         \n","                                                                 \n"," dense_6 (Dense)             (None, 128)               44859520  \n","                                                                 \n"," activation_15 (Activation)  (None, 128)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 128)               16512     \n","                                                                 \n"," activation_16 (Activation)  (None, 128)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 3)                 387       \n","                                                                 \n"," activation_17 (Activation)  (None, 3)                 0         \n","                                                                 \n","=================================================================\n","Total params: 45,320,451\n","Trainable params: 45,320,451\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/5\n","135/135 [==============================] - 42s 306ms/step - loss: 0.3297 - accuracy: 0.8607 - val_loss: 0.0055 - val_accuracy: 0.9978\n","Epoch 2/5\n","135/135 [==============================] - 40s 298ms/step - loss: 0.0721 - accuracy: 0.9867 - val_loss: 0.0017 - val_accuracy: 1.0000\n","Epoch 3/5\n","135/135 [==============================] - 37s 271ms/step - loss: 0.1055 - accuracy: 0.9815 - val_loss: 8.9882e-04 - val_accuracy: 1.0000\n","Epoch 4/5\n","135/135 [==============================] - 36s 270ms/step - loss: 0.0198 - accuracy: 0.9963 - val_loss: 4.3793e-04 - val_accuracy: 1.0000\n","Epoch 5/5\n","135/135 [==============================] - 40s 297ms/step - loss: 0.0455 - accuracy: 0.9919 - val_loss: 0.0035 - val_accuracy: 0.9989\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f99d44f6a10>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["#convertir el modelo en version de tensorflow lite\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(modelo)\n","#converter = tf.lite.TFLiteConverter.from_saved_model('gdrive/My Drive/tesis/modelos/modelo er-iv-di conv2d (128,128,256)(64,128,128) colab 300x300')\n","tflite_model = converter.convert()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8ODGuNIEVLi","executionInfo":{"status":"ok","timestamp":1643819358392,"user_tz":240,"elapsed":92696,"user":{"displayName":"Ivan Jose Duque Luna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiJhoMRg6vZLPIXpslz4bHdxaLre7D1LZX_BfQT=s64","userId":"01917523343114875724"}},"outputId":"ac4c2bad-2295-4ed5-fdbb-6697cb9e4abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /tmp/tmph3klki28/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /tmp/tmph3klki28/assets\n"]}]},{"cell_type":"code","source":["#guardar el modelo en version de tensorflow lite\n","\n","with open('gdrive/My Drive/tesis/modelos/modelolite er-iv-di conv2d (128,128,256)(64,128,128) colab 300x300', 'wb') as f:\n","  f.write(tflite_model)"],"metadata":{"id":"oxYoUP9KGk-v"},"execution_count":null,"outputs":[]}]}